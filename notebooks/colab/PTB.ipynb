{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pszemraj/ml4hc-s22-project01/blob/sync-notebooks/notebooks/colab/PTB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15a2bf69"
      },
      "source": [
        "# PTB Dataset\n"
      ],
      "id": "15a2bf69"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we trained various more or less complex models on the MITBIH dataset, made predictions and estimated their performance based on the accuracy, f1 score, AUROC and AUPRC metrics "
      ],
      "metadata": {
        "id": "rphK3mF-v7Kf"
      },
      "id": "rphK3mF-v7Kf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "HVH2t9YJwaIv"
      },
      "id": "HVH2t9YJwaIv"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e6b35d3d"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D,concatenate,\\\n",
        "Dense,Dropout,LSTM,Masking,Bidirectional,Flatten, Dropout,GRU,SimpleRNN,TimeDistributed, BatchNormalization, Activation, MaxPooling1D, GlobalMaxPooling1D, Conv1D\n",
        "from keras.models import Sequential,Model\n",
        "import h5py\n",
        "from sklearn.metrics import f1_score,accuracy_score, roc_auc_score, average_precision_score, precision_recall_curve, auc\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "import collections\n"
      ],
      "id": "e6b35d3d"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsFy_GpujCQ7",
        "outputId": "a958ebf6-5f5f-449a-8e6b-2fd47c0a03ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "hsFy_GpujCQ7"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ptbdb(base_path):\n",
        "    df_1 = pd.read_csv(os.path.join(base_path,\"data/ptbdb_normal.csv\"),\n",
        "                           header=None)\n",
        "    df_train = df_1.sample(frac=1)\n",
        "    df_2 = pd.read_csv(os.path.join(base_path,\"data/ptbdb_abnormal.csv\"),\n",
        "                          header=None)\n",
        "\n",
        "    df = pd.concat([df_1, df_2])\n",
        "\n",
        "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=1337, stratify=df[187])\n",
        "\n",
        "    Y = np.array(df_train[187].values).astype(np.int8)\n",
        "    X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "    Y_test = np.array(df_test[187].values).astype(np.int8)\n",
        "    X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n",
        "    \n",
        "\n",
        "    return X, X_test, Y, Y_test"
      ],
      "metadata": {
        "id": "Tfw-4ytfNfW6"
      },
      "id": "Tfw-4ytfNfW6",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "_drive_root = Path('/content/drive/MyDrive')\n",
        "top_level_files = {f.name:f for f in _drive_root.iterdir() if f.is_file()}\n",
        "file_bases = list(top_level_files.keys())\n",
        "_test = 'Ecuador 2018 budget.gsheet'\n"
      ],
      "metadata": {
        "id": "-7KvDGV9PAeL"
      },
      "id": "-7KvDGV9PAeL",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if _test in file_bases:\n",
        "    # peter is logged in\n",
        "    project = Path('/content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1')\n",
        "    path = str(project.resolve())\n",
        "else:\n",
        "    # it is not peter (and therefore lou) use standard path\n",
        "    path = '/content/drive/MyDrive/ETH/'\n",
        "\n",
        "print(f\"using data folder for loading etc as \\n\\t:{path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lI8sEaWBRwcI",
        "outputId": "c71c22b8-878e-4c4d-a60a-a16839c723c1"
      },
      "id": "lI8sEaWBRwcI",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using data folder for loading etc as \n",
            "\t:/content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_test, Y, Y_test = load_ptbdb(base_path= path)"
      ],
      "metadata": {
        "id": "GUGhUNSfNieA"
      },
      "id": "GUGhUNSfNieA",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple models\n",
        "We implemented the CNN baseline model, another simpler CNN model and a simple RNN"
      ],
      "metadata": {
        "id": "d0TOcI--wel4"
      },
      "id": "d0TOcI--wel4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ccfbd2d"
      },
      "source": [
        "### CNN BASELINE "
      ],
      "id": "1ccfbd2d"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DzG5oron2AOO"
      },
      "outputs": [],
      "source": [
        "def get_CNN_baseline_model():\n",
        "    nclass = 1\n",
        "    inp = Input(shape=(187, 1))\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
        "    img_1 = Convolution1D(16, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = GlobalMaxPool1D()(img_1)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.sigmoid, name=\"dense_3_ptbdb\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "id": "DzG5oron2AOO"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mNAw6kndP72e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d13e849b-e475-4ae0-8372-77a4a5c5ee13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 187, 1)]          0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 183, 16)           96        \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 179, 16)           1296      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 89, 16)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 89, 16)            0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 87, 32)            1568      \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 85, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 42, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 42, 32)            0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 40, 32)            3104      \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 38, 32)            3104      \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPooling  (None, 19, 32)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 19, 32)            0         \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 17, 256)           24832     \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 15, 256)           196864    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_3_ptbdb (Dense)       (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 254,641\n",
            "Trainable params: 254,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_acc improved from -inf to 0.79571, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 15s - loss: 0.5157 - acc: 0.7335 - val_loss: 0.4498 - val_acc: 0.7957 - lr: 0.0010 - 15s/epoch - 46ms/step\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_acc improved from 0.79571 to 0.84034, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 2s - loss: 0.3989 - acc: 0.8233 - val_loss: 0.4033 - val_acc: 0.8403 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_acc improved from 0.84034 to 0.88412, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 2s - loss: 0.3119 - acc: 0.8718 - val_loss: 0.2741 - val_acc: 0.8841 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_acc improved from 0.88412 to 0.92103, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 3s - loss: 0.2640 - acc: 0.8923 - val_loss: 0.2144 - val_acc: 0.9210 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_acc improved from 0.92103 to 0.93906, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 3s - loss: 0.2270 - acc: 0.9098 - val_loss: 0.1844 - val_acc: 0.9391 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_acc did not improve from 0.93906\n",
            "328/328 - 3s - loss: 0.2032 - acc: 0.9239 - val_loss: 0.1837 - val_acc: 0.9339 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 7: val_acc improved from 0.93906 to 0.94850, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 3s - loss: 0.1848 - acc: 0.9292 - val_loss: 0.1429 - val_acc: 0.9485 - lr: 0.0010 - 3s/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 8: val_acc did not improve from 0.94850\n",
            "328/328 - 2s - loss: 0.1581 - acc: 0.9404 - val_loss: 0.1577 - val_acc: 0.9365 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 9: val_acc improved from 0.94850 to 0.95107, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 2s - loss: 0.1545 - acc: 0.9415 - val_loss: 0.1283 - val_acc: 0.9511 - lr: 0.0010 - 2s/epoch - 7ms/step\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 10: val_acc improved from 0.95107 to 0.95536, saving model to baseline_CNN_ptbdb.h5\n",
            "328/328 - 2s - loss: 0.1365 - acc: 0.9485 - val_loss: 0.1137 - val_acc: 0.9554 - lr: 0.0010 - 2s/epoch - 7ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-61764aea2803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_baseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_test\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_baseline' is not defined"
          ]
        }
      ],
      "source": [
        "model = get_CNN_baseline_model()\n",
        "file_path = \"baseline_CNN_ptbdb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n",
        "model.fit(X, Y, epochs=10, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model_baseline.predict(X_test)\n",
        "pred_test = (pred_test>0.5).astype(np.int8)\n",
        "\n",
        "print('Baseline model results')\n",
        "f1 = f1_score(Y_test, pred_test)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "\n",
        "# calculate Receiver Operating Characteristics AUC\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "\n",
        "# calculate precision-recall curve\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "# calculate precision-recall AUC\n",
        "prc_auc = auc(recall, precision)\n",
        "print(\"AUPRC score : %s \"% prc_auc)\n"
      ],
      "id": "mNAw6kndP72e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8NxcE7B-Dsm"
      },
      "source": [
        "### CNN"
      ],
      "id": "N8NxcE7B-Dsm"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyZQ2wJ1-Cmr",
        "outputId": "c371c529-730f-470c-fb37-d53ea8309778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_8 (Conv1D)           (None, 185, 64)           256       \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 183, 32)           6176      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 5856)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 11714     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,146\n",
            "Trainable params: 18,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75107, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 1s - loss: 0.5443 - accuracy: 0.7259 - val_loss: 0.4948 - val_accuracy: 0.7511 - lr: 0.0010 - 1s/epoch - 35ms/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.75107 to 0.78798, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.4345 - accuracy: 0.7848 - val_loss: 0.4178 - val_accuracy: 0.7880 - lr: 0.0010 - 247ms/epoch - 6ms/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.78798 to 0.82146, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.3874 - accuracy: 0.8132 - val_loss: 0.3931 - val_accuracy: 0.8215 - lr: 0.0010 - 259ms/epoch - 6ms/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.82146 to 0.84034, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.3695 - accuracy: 0.8280 - val_loss: 0.3687 - val_accuracy: 0.8403 - lr: 0.0010 - 244ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.84034 to 0.84721, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.3478 - accuracy: 0.8472 - val_loss: 0.3520 - val_accuracy: 0.8472 - lr: 0.0010 - 265ms/epoch - 6ms/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.84721\n",
            "41/41 - 0s - loss: 0.3281 - accuracy: 0.8598 - val_loss: 0.3406 - val_accuracy: 0.8455 - lr: 0.0010 - 218ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.84721\n",
            "41/41 - 0s - loss: 0.3118 - accuracy: 0.8687 - val_loss: 0.3419 - val_accuracy: 0.8318 - lr: 0.0010 - 230ms/epoch - 6ms/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_accuracy improved from 0.84721 to 0.85579, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2971 - accuracy: 0.8792 - val_loss: 0.3241 - val_accuracy: 0.8558 - lr: 0.0010 - 280ms/epoch - 7ms/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_accuracy improved from 0.85579 to 0.87725, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2850 - accuracy: 0.8864 - val_loss: 0.2979 - val_accuracy: 0.8773 - lr: 0.0010 - 243ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.87725 to 0.89528, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2679 - accuracy: 0.8949 - val_loss: 0.2839 - val_accuracy: 0.8953 - lr: 0.0010 - 240ms/epoch - 6ms/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.89528\n",
            "41/41 - 0s - loss: 0.2621 - accuracy: 0.8991 - val_loss: 0.2787 - val_accuracy: 0.8850 - lr: 0.0010 - 209ms/epoch - 5ms/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_accuracy improved from 0.89528 to 0.90043, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2495 - accuracy: 0.9030 - val_loss: 0.2658 - val_accuracy: 0.9004 - lr: 0.0010 - 247ms/epoch - 6ms/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.90043\n",
            "41/41 - 0s - loss: 0.2465 - accuracy: 0.9034 - val_loss: 0.2631 - val_accuracy: 0.8961 - lr: 0.0010 - 214ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.90043 to 0.90386, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2399 - accuracy: 0.9086 - val_loss: 0.2575 - val_accuracy: 0.9039 - lr: 0.0010 - 239ms/epoch - 6ms/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.90386 to 0.90472, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2292 - accuracy: 0.9107 - val_loss: 0.2614 - val_accuracy: 0.9047 - lr: 0.0010 - 244ms/epoch - 6ms/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.90472 to 0.90987, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2299 - accuracy: 0.9099 - val_loss: 0.2450 - val_accuracy: 0.9099 - lr: 0.0010 - 242ms/epoch - 6ms/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.90987\n",
            "41/41 - 0s - loss: 0.2156 - accuracy: 0.9189 - val_loss: 0.2398 - val_accuracy: 0.9099 - lr: 0.0010 - 206ms/epoch - 5ms/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.90987\n",
            "41/41 - 0s - loss: 0.2126 - accuracy: 0.9224 - val_loss: 0.2422 - val_accuracy: 0.9073 - lr: 0.0010 - 211ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.90987 to 0.91159, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2114 - accuracy: 0.9219 - val_loss: 0.2355 - val_accuracy: 0.9116 - lr: 0.0010 - 241ms/epoch - 6ms/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_accuracy improved from 0.91159 to 0.91330, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2067 - accuracy: 0.9233 - val_loss: 0.2335 - val_accuracy: 0.9133 - lr: 0.0010 - 245ms/epoch - 6ms/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_accuracy improved from 0.91330 to 0.91502, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2034 - accuracy: 0.9254 - val_loss: 0.2292 - val_accuracy: 0.9150 - lr: 0.0010 - 245ms/epoch - 6ms/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_accuracy improved from 0.91502 to 0.91931, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.2040 - accuracy: 0.9234 - val_loss: 0.2226 - val_accuracy: 0.9193 - lr: 0.0010 - 246ms/epoch - 6ms/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.91931\n",
            "41/41 - 0s - loss: 0.1996 - accuracy: 0.9269 - val_loss: 0.2338 - val_accuracy: 0.9185 - lr: 0.0010 - 208ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.91931\n",
            "41/41 - 0s - loss: 0.2016 - accuracy: 0.9228 - val_loss: 0.2430 - val_accuracy: 0.9047 - lr: 0.0010 - 210ms/epoch - 5ms/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.91931\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "41/41 - 0s - loss: 0.1963 - accuracy: 0.9283 - val_loss: 0.2199 - val_accuracy: 0.9159 - lr: 0.0010 - 210ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_accuracy improved from 0.91931 to 0.92361, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1CNN_PTB.h5\n",
            "41/41 - 0s - loss: 0.1835 - accuracy: 0.9359 - val_loss: 0.2137 - val_accuracy: 0.9236 - lr: 1.0000e-04 - 247ms/epoch - 6ms/step\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.92361\n",
            "41/41 - 0s - loss: 0.1816 - accuracy: 0.9368 - val_loss: 0.2122 - val_accuracy: 0.9219 - lr: 1.0000e-04 - 209ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.92361\n",
            "41/41 - 0s - loss: 0.1808 - accuracy: 0.9365 - val_loss: 0.2145 - val_accuracy: 0.9236 - lr: 1.0000e-04 - 209ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.92361\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "41/41 - 0s - loss: 0.1803 - accuracy: 0.9376 - val_loss: 0.2115 - val_accuracy: 0.9236 - lr: 1.0000e-04 - 208ms/epoch - 5ms/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.92361\n",
            "41/41 - 0s - loss: 0.1793 - accuracy: 0.9378 - val_loss: 0.2108 - val_accuracy: 0.9227 - lr: 1.0000e-05 - 207ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.92361\n",
            "41/41 - 0s - loss: 0.1792 - accuracy: 0.9372 - val_loss: 0.2108 - val_accuracy: 0.9227 - lr: 1.0000e-05 - 211ms/epoch - 5ms/step\n",
            "Epoch 31: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb9b0288fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "CNN_model = Sequential()\n",
        "CNN_model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(187,1)))\n",
        "CNN_model.add(Conv1D(32, kernel_size=3, activation='relu'))\n",
        "CNN_model.add(Flatten())\n",
        "CNN_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "file_path = path + \"CNN_PTB.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "red = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, red]\n",
        "\n",
        "CNN_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "CNN_model.summary()\n",
        "\n",
        "CNN_model.fit(X, Y, epochs=100,batch_size=256, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
      ],
      "id": "PyZQ2wJ1-Cmr"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "we7SKNarCx9j",
        "outputId": "bb1c5e18-c414-4ba1-ea3f-41a4315805d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy score : 0.9209893507385778 \n",
            "Test f1 score : 0.9207445739136773 \n",
            "AUROC score : 0.8985282719735986 \n",
            "AUPRC score : 0.9638897863485523 \n"
          ]
        }
      ],
      "source": [
        "CNN_model.load_weights(file_path)\n",
        "pred_test = CNN_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "we7SKNarCx9j"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aeddb17"
      },
      "source": [
        "### RNN"
      ],
      "id": "9aeddb17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5472e4d7",
        "outputId": "34eea471-80a8-489b-a43f-0874519d1e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " masking (Masking)           (None, 187, 1)            0         \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                4224      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,354\n",
            "Trainable params: 4,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.69185, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1RNN_PTB.h5\n",
            "41/41 - 11s - loss: 0.5625 - accuracy: 0.7180 - val_loss: 0.5601 - val_accuracy: 0.6918 - lr: 0.0010 - 11s/epoch - 262ms/step\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.69185 to 0.69957, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1RNN_PTB.h5\n",
            "41/41 - 9s - loss: 0.5485 - accuracy: 0.7188 - val_loss: 0.5748 - val_accuracy: 0.6996 - lr: 0.0010 - 9s/epoch - 218ms/step\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.69957\n",
            "41/41 - 8s - loss: 0.5503 - accuracy: 0.7206 - val_loss: 0.5655 - val_accuracy: 0.6987 - lr: 0.0010 - 8s/epoch - 205ms/step\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.69957 to 0.70129, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1RNN_PTB.h5\n",
            "41/41 - 9s - loss: 0.5347 - accuracy: 0.7243 - val_loss: 0.5574 - val_accuracy: 0.7013 - lr: 0.0010 - 9s/epoch - 213ms/step\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.70129 to 0.71845, saving model to /content/drive/MyDrive/ETHZ-2022-S/ML-healthcare-projects/project1RNN_PTB.h5\n",
            "41/41 - 9s - loss: 0.5333 - accuracy: 0.7220 - val_loss: 0.5623 - val_accuracy: 0.7185 - lr: 0.0010 - 9s/epoch - 218ms/step\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.71845\n",
            "41/41 - 8s - loss: 0.5293 - accuracy: 0.7245 - val_loss: 0.5392 - val_accuracy: 0.7107 - lr: 0.0010 - 8s/epoch - 204ms/step\n",
            "Epoch 7/10\n"
          ]
        }
      ],
      "source": [
        "RNN_model=Sequential()\n",
        "RNN_model.add(Masking(mask_value=0.,input_shape=(187,1)))\n",
        "RNN_model.add(SimpleRNN(64))\n",
        "RNN_model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "file_path = path+ \"RNN_PTB.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, redonplat]\n",
        "\n",
        "RNN_model.compile(optimizer=optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "RNN_model.summary()\n",
        "\n",
        "RNN_model.fit(X, Y, epochs=10,batch_size=256, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
      ],
      "id": "5472e4d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e4d116d"
      },
      "outputs": [],
      "source": [
        "RNN_model.load_weights(file_path)\n",
        "pred_test = RNN_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "5e4d116d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More advanced models\n",
        "Based on [1, 2], we have implemented simple LSTM, GRU and MLP models. Then, by trying to improve these models and looking at other studies [3], we build more complex models : Bidirectional LSTM and Bidirectional GRU."
      ],
      "metadata": {
        "id": "8q959PyKw_DT"
      },
      "id": "8q959PyKw_DT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBkhdt9WOOCZ"
      },
      "source": [
        "### LSTM"
      ],
      "id": "jBkhdt9WOOCZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEZlPsjwOQAM"
      },
      "outputs": [],
      "source": [
        "LSTM_model = Sequential()\n",
        "LSTM_model.add(Masking(mask_value=0.,input_shape=(187,1)))\n",
        "LSTM_model.add(BatchNormalization())\n",
        "LSTM_model.add(LSTM(64, dropout=0.2))\n",
        "LSTM_model.add(BatchNormalization())\n",
        "LSTM_model.add(Dense(128,activation='relu'))\n",
        "LSTM_model.add(BatchNormalization())\n",
        "LSTM_model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "file_path = path+ \"LTSM_ptb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "red = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, red]\n",
        "\n",
        "LSTM_model.compile(optimizer=optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "LSTM_model.summary()\n",
        "\n",
        "LSTM_model.fit(X, Y, epochs=100,batch_size=256, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
      ],
      "id": "LEZlPsjwOQAM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfKFdeJUS-mi"
      },
      "outputs": [],
      "source": [
        "LSTM_model.load_weights(file_path)\n",
        "pred_test = LSTM_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "lfKFdeJUS-mi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVvkieFcTIdN"
      },
      "source": [
        "### GRU"
      ],
      "id": "iVvkieFcTIdN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKHwB0z3TKpu"
      },
      "outputs": [],
      "source": [
        "GRU_model=Sequential()\n",
        "GRU_model.add(Masking(mask_value=0.,input_shape=(187,1)))\n",
        "GRU_model.add(BatchNormalization())\n",
        "GRU_model.add(GRU(187))\n",
        "GRU_model.add(BatchNormalization())\n",
        "GRU_model.add(Dense(64,activation='relu'))\n",
        "GRU_model.add(BatchNormalization())\n",
        "GRU_model.add(Dense(2,activation='softmax'))\n",
        "\n",
        "file_path = path + \"GRU_ptb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"acc\", mode=\"max\", patience=5, verbose=1)\n",
        "red = ReduceLROnPlateau(monitor=\"acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, red]\n",
        "\n",
        "GRU_model.compile(optimizer=optimizers.Adam(0.001), loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "GRU_model.summary()\n",
        "\n",
        "GRU_model.fit(X, Y, epochs=100,batch_size=256, verbose=2, callbacks=callbacks_list)"
      ],
      "id": "yKHwB0z3TKpu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sniGYpdxTN7d"
      },
      "outputs": [],
      "source": [
        "GRU_model.load_weights(file_path)\n",
        "pred_test = GRU_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "sniGYpdxTN7d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_eRuemzU90y"
      },
      "source": [
        "### MLP"
      ],
      "id": "6_eRuemzU90y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma92xFx8U-Fs"
      },
      "outputs": [],
      "source": [
        "train, test, y_train, y_test = load_ptbdb()\n",
        "train, test = train[:,:,0], test[:,:,0]"
      ],
      "id": "Ma92xFx8U-Fs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-FQAulAU-u5"
      },
      "outputs": [],
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(200,), activation='tanh',\n",
        "                    random_state=1).fit(train, y_train)\n",
        "\n",
        "pred_test = clf.predict(test)\n",
        "acc = accuracy_score(y_test, pred_test)\n",
        "f1 = f1_score(y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "Z-FQAulAU-u5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8k1prPzTaJ_"
      },
      "source": [
        "### Bidirectional GRU"
      ],
      "id": "j8k1prPzTaJ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS5TqVn_Tdn7"
      },
      "outputs": [],
      "source": [
        "BidirGRU_model=Sequential()\n",
        "BidirGRU_model.add(Masking(mask_value=0.,input_shape=(187,1)))\n",
        "BidirGRU_model.add(BatchNormalization())\n",
        "BidirGRU_model.add(Bidirectional(GRU(100,return_sequences=True)))\n",
        "BidirGRU_model.add(Dropout(0.3))\n",
        "BidirGRU_model.add(Bidirectional(GRU(100)))\n",
        "BidirGRU_model.add(Dropout(0.1))\n",
        "BidirGRU_model.add(BatchNormalization())\n",
        "BidirGRU_model.add(Dense(2,activation=activations.softmax))\n",
        "\n",
        "\n",
        "file_path = path+'BidirGRU_ptb.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "red = ReduceLROnPlateau(monitor=\"accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, red]\n",
        "\n",
        "BidirGRU_model.compile(optimizer=optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "BidirGRU_model.summary()\n",
        "\n",
        "#BidirGRU_model.fit(X, Y, epochs=100,batch_size=256, verbose=2, callbacks=callbacks_list)"
      ],
      "id": "tS5TqVn_Tdn7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-8u-s2rTezE"
      },
      "outputs": [],
      "source": [
        "BidirGRU_model.load_weights(file_path)\n",
        "pred_test = BidirGRU_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "F-8u-s2rTezE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1A4AKqzLRH8"
      },
      "source": [
        "### Bidirectional LSTM"
      ],
      "id": "j1A4AKqzLRH8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a78c057e"
      },
      "outputs": [],
      "source": [
        "BiLSTM_model = Sequential()\n",
        "BiLSTM_model.add(Masking(mask_value=0.,input_shape=(187,1)))\n",
        "BiLSTM_model.add(BatchNormalization())\n",
        "BiLSTM_model.add(Bidirectional(LSTM(100, return_sequences=True)))\n",
        "BiLSTM_model.add(Dropout(0.3))\n",
        "BiLSTM_model.add(Bidirectional(LSTM(100)))\n",
        "BiLSTM_model.add(BatchNormalization())\n",
        "BiLSTM_model.add(Dense(64, activation='relu'))\n",
        "BiLSTM_model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "file_path = path+ \"BILSTM187_ptb.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=5, verbose=1)\n",
        "red = ReduceLROnPlateau(monitor=\"val_accuracy\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint,early, red]\n",
        "\n",
        "BiLSTM_model.compile(optimizer=optimizers.Adam(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "BiLSTM_model.summary()\n",
        "\n",
        "BiLSTM_model.fit(X, Y, epochs=100,batch_size=256, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
      ],
      "id": "a78c057e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6290deb4"
      },
      "outputs": [],
      "source": [
        "BiLSTM_model.load_weights(file_path)\n",
        "\n",
        "\n",
        ".fit(train,y_train)\n",
        "pred_test = BiLSTM_model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "f1 = f1_score(Y_test, pred_test, average='weighted')\n",
        "roc_auc = roc_auc_score(Y_test, pred_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, pred_test)\n",
        "prc_auc = auc(recall, precision)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "print(\"AUROC score : %s \"% roc_auc)\n",
        "print(\"AUPRC score : %s \"% prc_auc)"
      ],
      "id": "6290deb4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters estimation\n",
        "We trained and tested our models with several different parameters, increasing or decreasing the number of hidden units or the batch size and modifying the architecture by adding or removing some layers. We then made choices by trying to combine good performance in terms of metrics (accuracy, f1_score, AUROC and AUPRC) and computational cost."
      ],
      "metadata": {
        "id": "DBHVgAhIxTcq"
      },
      "id": "DBHVgAhIxTcq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n"
      ],
      "metadata": {
        "id": "QaBrf1lNxb5D"
      },
      "id": "QaBrf1lNxb5D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Zahra Ebrahimi, Mohammad Loni, Masoud Daneshtalab, Arash Gharehbaghi - A review on deep learning methods for ECG arrhythmia classification\n"
      ],
      "metadata": {
        "id": "VjDhccOjxdf4"
      },
      "id": "VjDhccOjxdf4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2] Chung, Gulcehre, Cho,& Bengio, 2014  Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555.\n"
      ],
      "metadata": {
        "id": "n1R7Z01Zxd5q"
      },
      "id": "n1R7Z01Zxd5q"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3]   Yildirim - A novel wavelet sequence based on deep bidirectional LSTM network model for ECG signal classification"
      ],
      "metadata": {
        "id": "uK12L4tnxd-J"
      },
      "id": "uK12L4tnxd-J"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PTB_GDriveLogic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}