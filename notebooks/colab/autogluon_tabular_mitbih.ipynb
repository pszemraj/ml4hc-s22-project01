{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autogluon-tabular-mitbih.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNtFxbQ47sdvQvzrM2BIkDp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pszemraj/ml4hc-s22-project01/blob/add-gluon-autoML/notebooks/colab/autogluon_tabular_mitbih.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> autogluon for MIT-BIH dataset <center>\n",
        "\n",
        "- see how autoML does on MIT-BIH dataset\n",
        "- docs can be found [here](https://auto.gluon.ai/stable/tutorials/tabular_prediction/tabular-quickstart.html)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CIL08BghY2R_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## setup"
      ],
      "metadata": {
        "id": "__2Cz9lIti4y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "LrDWdEzv3LaX"
      },
      "outputs": [],
      "source": [
        "#@markdown add auto-Colab formatting with `IPython.display`\n",
        "from IPython.display import HTML, display\n",
        "# colab formatting\n",
        "def set_css():\n",
        "    display(\n",
        "        HTML(\n",
        "            \"\"\"\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  \"\"\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "get_ipython().events.register(\"pre_run_cell\", set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "mIZn1aQe1rYk",
        "outputId": "f8e2ca8a-25c8-4ea9-aa4d-6b5bb88a3f2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 27 05:06:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#@title print out GPU info\n",
        "#@markdown this is the Colab-allocated GPU. If the output here says it fails, no\n",
        "#@markdown GPU is being used. go to runtime at the top of your colab to set runtime to GPU.\n",
        "\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon -q "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wtovw8wMXGnF",
        "outputId": "423d9380-2108-4299-add5-8923e262d8ae"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 188 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48 kB 6.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 60.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 267 kB 63.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 54.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 802 kB 48.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 57.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54.7 MB 16.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 296 kB 26.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166.7 MB 19 kB/s \n",
            "\u001b[K     |████████████████████████████████| 187 kB 64.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 54.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 56.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 398 kB 71.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 527 kB 76.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 75.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 248 kB 70.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 431 kB 75.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 65.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 25.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 11.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 134 kB 74.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 952 kB 60.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 225 kB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 71.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 68.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 67.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 116 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 73 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 709 kB/s \n",
            "\u001b[?25h  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7c785a46-0a08-4b1f-8177-bd2d67ecbf80",
        "id": "OeLdsRpQwarZ"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title define source data parameters\n",
        "\n",
        "#@markdown - these can also be loaded from gdrive, but I am lazy and `wget` does not require login\n",
        "\n",
        "mitbih_train_url = \"https://www.dropbox.com/s/2ks8s82tm7jvhse/torchfmt_mitbih_train.csv?dl=1\" #@param {type:\"string\"}\n",
        "mitbih_train_filename = \"mitbih_train.csv\" #@param {type:\"string\"}\n",
        "mitbih_test_url = \"https://www.dropbox.com/s/nbaxenoehvqmqnm/torchfmt_mitbih_test.csv?dl=1\" #@param {type:\"string\"}\n",
        "mitbih_test_filename = \"mitbih_test.csv\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title autogluon parameters \n",
        "\n",
        "#@markdown - `max_time_fitting` is in seconds\n",
        "\n",
        "max_time_fitting =  10800#@param {type:\"integer\"}\n",
        "fit_preset = \"best_quality\" #@param [\"best_quality\", \"high_quality\"]\n",
        "metric = 'accuracy'  #@param [\"roc_auc\", \"accuracy\", \"f1\"]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "cellView": "form",
        "id": "F_W9K8KuYYV5",
        "outputId": "2b24ff33-3c6f-4985-a693-5b46ced7dc8d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### data"
      ],
      "metadata": {
        "id": "LmhjOOpMtn6U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "backed-render",
        "outputId": "422e7ebc-32b3-47b2-c468-5a2c72310be2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "!wget $mitbih_train_url -O $mitbih_train_filename -q\n",
        "!wget $mitbih_test_url -O $mitbih_test_filename -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "example_df = pd.read_csv(mitbih_train_filename)\n",
        "data_cols = list(example_df.columns)\n",
        "_target = data_cols[-1]\n",
        "data_cols.pop()\n",
        "_predictors = data_cols # all other columns are numerical predictors\n",
        "\n",
        "print(f\"the target colname is {_target} and\\nthe predictor colnames 5 of {len(_predictors)} are {_predictors[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8Enc_pKGYSR7",
        "outputId": "d910fd31-e0e9-40a5-b573-2df2cf7491fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the target colname is class_label and\n",
            "the predictor colnames 5 of 187 are ['feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## fit model"
      ],
      "metadata": {
        "id": "POoVU2rQtqKy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 929
        },
        "id": "4Hqk56tMWg0p",
        "outputId": "a0875fb4-5e5d-470e-c17e-f12bffc86c52"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20220327_050850/\"\n",
            "Presets specified: ['best_quality']\n",
            "Beginning AutoGluon training ... Time limit = 10800s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20220327_050850/\"\n",
            "AutoGluon Version:  0.4.0\n",
            "Python Version:     3.7.13\n",
            "Operating System:   Linux\n",
            "Train Data Rows:    87554\n",
            "Train Data Columns: 187\n",
            "Label Column: class_label\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
            "\t5 unique label values:  ['N', 'S', 'V', 'F', 'Q']\n",
            "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Train Data Class Count: 5\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    12000.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 130.98 MB (1.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 187 | ['feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 187 | ['feat_0', 'feat_1', 'feat_2', 'feat_3', 'feat_4', ...]\n",
            "\t2.6s = Fit runtime\n",
            "\t187 features in original data used to generate 187 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 130.98 MB (1.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 3.04s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 7196.17s of the 10796.94s of remaining time.\n",
            "\t0.9749\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t321.13s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 6871.93s of the 10472.7s of remaining time.\n",
            "\t0.9757\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t312.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6556.75s of the 10157.52s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "train_data = TabularDataset(mitbih_train_filename)\n",
        "test_data = TabularDataset(mitbih_test_filename)\n",
        "predictor = TabularPredictor(\n",
        "                            label=_target,\n",
        "                             eval_metric=metric,\n",
        "                             ).fit(\n",
        "                                    train_data, \n",
        "                                    time_limit=max_time_fitting,\n",
        "                                    presets=fit_preset,\n",
        "                                   ag_args_fit={'num_gpus': torch.cuda.device_count()}\n",
        "                                   )  \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = predictor.fit_summary(show_plot=True)\n"
      ],
      "metadata": {
        "id": "o42mli2QbI_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extra_metrics=['accuracy', 'roc_auc', 'log_loss', 'f1']\n",
        "\n",
        "leaderboard = predictor.leaderboard(test_data, extra_metrics=extra_metrics)\n",
        "\n",
        "leaderboard"
      ],
      "metadata": {
        "id": "vGowP8mTZcj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## export results"
      ],
      "metadata": {
        "id": "eGQ0CXL-tuo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl -q"
      ],
      "metadata": {
        "id": "dlm8uQHocsU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "_cwd = Path.cwd()\n",
        "\n",
        "csv_path = _cwd / \"ptbdb_autogluon_results.csv\"\n",
        "xlsx_path = _cwd / \"ptbdb_autogluon_results.xlsx\"\n",
        "\n",
        "leaderboard.to_csv(csv_path)\n",
        "leaderboard.to_excel(xlsx_path)\n"
      ],
      "metadata": {
        "id": "ubdzxFaRq4NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import time\n",
        "files.download(csv_path)\n",
        "time.sleep(3)\n",
        "files.download(xlsx_path)\n"
      ],
      "metadata": {
        "id": "mSmfBk5prigT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wi1KTFBSrrAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}